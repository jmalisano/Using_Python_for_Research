{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use papers for reference\n",
    "#https://www.sciencedirect.com/science/article/pii/S0021929015005096?casa_token=bRS9rMcnv9EAAAAA:g4I7cpGwxDV1ewaLAnG-kkoYe4XNth9t9Nrc_00GZUX25CyfkEZ1WECXEhp0s54Gi_5XlOCHlqI\n",
    "#https://ieeexplore.ieee.org/abstract/document/6981909?casa_token=PO2iJ-5Sa6EAAAAA:fJTGR6JuxQtKaY-0cJ1K_aRzaDoP7DrkkhGop3fMuPfah1svKK3kieIRckTjg9SIqAlNN6laZw\n",
    "\n",
    "#the answer is in frequency analysis\n",
    "#https://www.kdnuggets.com/2020/02/audio-data-analysis-deep-learning-python-part-1.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_time = pd.read_csv(\"train_time_series.csv\").drop(columns = [\"timestamp\",\"UTC time\",\"accuracy\"])\n",
    "tr_lab = pd.read_csv(\"train_labels.csv\").drop(columns = [\"timestamp\",\"UTC time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_time.rename(columns = {\"Unnamed: 0\":\"measurement\"}, inplace=True)\n",
    "tr_lab.rename(columns = {\"Unnamed: 0\":\"measurement\"}, inplace=True)\n",
    "\n",
    "df = tr_time.merge(tr_lab,on=\"measurement\")  #remove / move??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>measurement</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3739</th>\n",
       "      <td>24325</td>\n",
       "      <td>0.024384</td>\n",
       "      <td>-0.710709</td>\n",
       "      <td>0.030304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3740</th>\n",
       "      <td>24326</td>\n",
       "      <td>0.487228</td>\n",
       "      <td>-1.099136</td>\n",
       "      <td>-0.015213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3741</th>\n",
       "      <td>24327</td>\n",
       "      <td>0.369446</td>\n",
       "      <td>-0.968506</td>\n",
       "      <td>0.036713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3742</th>\n",
       "      <td>24328</td>\n",
       "      <td>0.167877</td>\n",
       "      <td>-0.802826</td>\n",
       "      <td>0.049805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3743</th>\n",
       "      <td>24329</td>\n",
       "      <td>0.689346</td>\n",
       "      <td>-0.991043</td>\n",
       "      <td>0.034973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      measurement         x         y         z\n",
       "3739        24325  0.024384 -0.710709  0.030304\n",
       "3740        24326  0.487228 -1.099136 -0.015213\n",
       "3741        24327  0.369446 -0.968506  0.036713\n",
       "3742        24328  0.167877 -0.802826  0.049805\n",
       "3743        24329  0.689346 -0.991043  0.034973"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_time.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>measurement</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20589</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20599</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20609</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20619</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20629</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>24289</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>24299</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>24309</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>24319</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>24329</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>375 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     measurement  label\n",
       "0          20589      1\n",
       "1          20599      1\n",
       "2          20609      1\n",
       "3          20619      1\n",
       "4          20629      1\n",
       "..           ...    ...\n",
       "370        24289      4\n",
       "371        24299      4\n",
       "372        24309      4\n",
       "373        24319      4\n",
       "374        24329      4\n",
       "\n",
       "[375 rows x 2 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Standardise X,Y,Z accels\n",
    "# std = StandardScaler()\n",
    "# for k in [\"x\", \"y\", \"z\"]:\n",
    "#     tr_time[k] = std.fit_transform(tr_time[k].values.reshape(-1,1))\n",
    "# tr_time.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accel_mag(accels):\n",
    "    \"\"\"takes an array containing x,y,z accelerations, calculates their magnitude\"\"\"\n",
    "    return np.sqrt(np.sum(accels**2))\n",
    "\n",
    "def accel_var(accels):\n",
    "    \"\"\"takes an array containing unidirectional accelaration, calculates and returns the variance\"\"\"\n",
    "    return np.var(accels)\n",
    "\n",
    "def calc_energy(accels, num_observations=10):\n",
    "    \"\"\"\"\"\"\n",
    "    return (np.sum(accels**2)/3)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if the above doesn't work aggregate the x's, the y's, the z's togehter - maybe use a sum or mean? then use x, y,z as input X for machine learning\n",
    "previous = 0\n",
    "\n",
    "for i in tr_lab.measurement:\n",
    "    boolinds = pd.Series((tr_time.measurement.values <= i + 5) & (tr_time.measurement.values > previous))\n",
    "    num_observations = sum(boolinds)\n",
    "    step = tr_time[boolinds.values]\n",
    "\n",
    "    #calculate some values of x, y, z from the step\n",
    "\n",
    "#     sums = []\n",
    "    means = []\n",
    "#     abs_sums = []\n",
    "    abs_means = []\n",
    "\n",
    "\n",
    "    for j in [\"x\", \"y\", \"z\"]:\n",
    "        accel_sum = np.sum(step[j].values)\n",
    "        sums.append(accel_sum)\n",
    "        accel_mean = np.mean(step[j].values)\n",
    "        means.append(accel_mean)\n",
    "        abs_sum = np.sum(np.absolute(step[j].values))\n",
    "        abs_sums.append(abs_sum)\n",
    "        abs_mean = np.mean(np.absolute(step[j].values))\n",
    "        abs_means.append(abs_mean)\n",
    "\n",
    "#     tr_lab.loc[tr_lab.measurement == i, \"x_sum\"] = sums[0]\n",
    "#     tr_lab.loc[tr_lab.measurement == i, \"y_sum\"] = sums[1]\n",
    "#     tr_lab.loc[tr_lab.measurement == i, \"z_sum\"] = sums[2]\n",
    "    tr_lab.loc[tr_lab.measurement == i, \"x_mean\"] = means[0]\n",
    "    tr_lab.loc[tr_lab.measurement == i, \"y_mean\"] = means[1]\n",
    "    tr_lab.loc[tr_lab.measurement == i, \"z_mean\"] = means[2]\n",
    "#     tr_lab.loc[tr_lab.measurement == i, \"x_abs_sum\"] = abs_sums[0]\n",
    "#     tr_lab.loc[tr_lab.measurement == i, \"y_abs_sum\"] = abs_sums[1]\n",
    "#     tr_lab.loc[tr_lab.measurement == i, \"z_abs_sum\"] = abs_sums[2]\n",
    "    tr_lab.loc[tr_lab.measurement == i, \"x_abs_mean\"] = abs_means[0]\n",
    "    tr_lab.loc[tr_lab.measurement == i, \"y_abs_mean\"] = abs_means[1]\n",
    "    tr_lab.loc[tr_lab.measurement == i, \"z_abs_mean\"] = abs_means[2]\n",
    "\n",
    "\n",
    "    #calculate magnitude of acceleration and variation of acceleration for the step - maybe delete later    \n",
    "    accels = step.loc[:,(\"x\",\"y\",\"z\")]\n",
    "    mags = accels.apply(accel_mag, axis=\"columns\")\n",
    "#    tr_lab.loc[tr_lab.measurement == i, \"sum_accel_mag\"] = np.sum(mags)\n",
    "    tr_lab.loc[tr_lab.measurement == i, \"mean_accel_mag\"] = np.mean(mags)\n",
    "    \n",
    "#     tr_lab.loc[tr_lab.measurement == i, \"var_x\"] = accel_var(accels.x)\n",
    "#     tr_lab.loc[tr_lab.measurement == i, \"var_y\"] = accel_var(accels.y)\n",
    "#     tr_lab.loc[tr_lab.measurement == i, \"var_z\"] = accel_var(accels.z)\n",
    "    tr_lab.loc[tr_lab.measurement == i, \"var_mag\"] = accel_var(mags)\n",
    "    \n",
    "    energy = accels.apply(calc_energy, axis=\"columns\")/num_observations\n",
    "    tr_lab.loc[tr_lab.measurement == i, \"mean_energy\"] = np.mean(energy)\n",
    "#    tr_lab.loc[tr_lab.measurement == i, \"sum_energy\"] = np.sum(energy)\n",
    "    \n",
    "    previous = i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#########BACKUP\n",
    "\n",
    "\n",
    "#if the above doesn't work aggregate the x's, the y's, the z's togehter - maybe use a sum or mean? then use x, y,z as input X for machine learning\n",
    "previous = 0\n",
    "\n",
    "for i in tr_lab.measurement:\n",
    "    \n",
    "    \n",
    "    boolinds = pd.Series((tr_time.measurement.values <= i) & (tr_time.measurement.values > previous))\n",
    "    num_observations = sum(boolinds)\n",
    "    step = tr_time[boolinds.values]\n",
    "\n",
    "    #calculate some values of x, y, z from the step\n",
    "\n",
    "#     sums = []\n",
    "    means = []\n",
    "#     abs_sums = []\n",
    "    abs_means = []\n",
    "\n",
    "\n",
    "    for j in [\"x\", \"y\", \"z\"]:\n",
    "        accel_sum = np.sum(step[j].values)\n",
    "        sums.append(accel_sum)\n",
    "        accel_mean = np.mean(step[j].values)\n",
    "        means.append(accel_mean)\n",
    "        abs_sum = np.sum(np.absolute(step[j].values))\n",
    "        abs_sums.append(abs_sum)\n",
    "        abs_mean = np.mean(np.absolute(step[j].values))\n",
    "        abs_means.append(abs_mean)\n",
    "\n",
    "#     tr_lab.loc[tr_lab.measurement == i, \"x_sum\"] = sums[0]\n",
    "#     tr_lab.loc[tr_lab.measurement == i, \"y_sum\"] = sums[1]\n",
    "#     tr_lab.loc[tr_lab.measurement == i, \"z_sum\"] = sums[2]\n",
    "    tr_lab.loc[tr_lab.measurement == i, \"x_mean\"] = means[0]\n",
    "    tr_lab.loc[tr_lab.measurement == i, \"y_mean\"] = means[1]\n",
    "    tr_lab.loc[tr_lab.measurement == i, \"z_mean\"] = means[2]\n",
    "#     tr_lab.loc[tr_lab.measurement == i, \"x_abs_sum\"] = abs_sums[0]\n",
    "#     tr_lab.loc[tr_lab.measurement == i, \"y_abs_sum\"] = abs_sums[1]\n",
    "#     tr_lab.loc[tr_lab.measurement == i, \"z_abs_sum\"] = abs_sums[2]\n",
    "    tr_lab.loc[tr_lab.measurement == i, \"x_abs_mean\"] = abs_means[0]\n",
    "    tr_lab.loc[tr_lab.measurement == i, \"y_abs_mean\"] = abs_means[1]\n",
    "    tr_lab.loc[tr_lab.measurement == i, \"z_abs_mean\"] = abs_means[2]\n",
    "\n",
    "\n",
    "    #calculate magnitude of acceleration and variation of acceleration for the step - maybe delete later    \n",
    "    accels = step.loc[:,(\"x\",\"y\",\"z\")]\n",
    "    mags = accels.apply(accel_mag, axis=\"columns\")\n",
    "#    tr_lab.loc[tr_lab.measurement == i, \"sum_accel_mag\"] = np.sum(mags)\n",
    "    tr_lab.loc[tr_lab.measurement == i, \"mean_accel_mag\"] = np.mean(mags)\n",
    "    \n",
    "#     tr_lab.loc[tr_lab.measurement == i, \"var_x\"] = accel_var(accels.x)\n",
    "#     tr_lab.loc[tr_lab.measurement == i, \"var_y\"] = accel_var(accels.y)\n",
    "#     tr_lab.loc[tr_lab.measurement == i, \"var_z\"] = accel_var(accels.z)\n",
    "    tr_lab.loc[tr_lab.measurement == i, \"var_mag\"] = accel_var(mags)\n",
    "    \n",
    "    energy = accels.apply(calc_energy, axis=\"columns\")/num_observations\n",
    "    tr_lab.loc[tr_lab.measurement == i, \"mean_energy\"] = np.mean(energy)\n",
    "#    tr_lab.loc[tr_lab.measurement == i, \"sum_energy\"] = np.sum(energy)\n",
    "    \n",
    "    previous = i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariates = tr_lab.drop(columns = ['measurement', 'label']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tr_lab['label']\n",
    "\n",
    "#data to analyse\n",
    "cols = tr_lab.drop(columns = ['measurement', 'label']).columns\n",
    "#cols = ['sum_accel_mag']\n",
    "X_train = tr_lab[cols]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale the data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_scaled = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (375, 9)\n",
      "Reduced shape: (375, 2)\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca.fit(X_scaled)\n",
    "X_pca = pca.transform(X_scaled)\n",
    "print(\"Original shape: {}\".format(str(X_scaled.shape)))\n",
    "print(\"Reduced shape: {}\".format(str(X_pca.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 8, 'n_estimators': 250}"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    \"n_estimators\":[5,10,50,100,250],\n",
    "    \"max_depth\":[2,4,8,16,32,None]   \n",
    "}\n",
    "\n",
    "cv = GridSearchCV(rfc,parameters,cv=5)\n",
    "cv.fit(X_train,y_train)\n",
    "best_params = cv.best_params_ \n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=8, n_estimators=250)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialise the random forest model with best hyperparameters and train\n",
    "rfc = RandomForestClassifier(max_depth = best_params['max_depth'], n_estimators = best_params['n_estimators'])\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6746666666666667"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(rfc,X_train, y_train, cv=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 45, 'weights': 'distance'}"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "parameters = {\n",
    "    \"n_neighbors\":np.arange(0,100,5),\n",
    "    \"weights\":['uniform', 'distance']\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(knn,parameters,cv=5)\n",
    "cv.fit(X_pca,y_train)\n",
    "best_params = cv.best_params_ \n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=45, weights='distance')"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialise the random forest model with best hyperparameters and train\n",
    "knn = KNeighborsClassifier(n_neighbors = best_params['n_neighbors'], weights = best_params['weights'])\n",
    "knn.fit(X_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6346666666666667"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(knn,X_pca, y_train, cv=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
